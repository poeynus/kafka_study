# 카프카 공부 정리

## 카프카란?

***메시징 시스템***

비동기 통신 프로토콜을 지닌 즉각적인 응답이 필요 하지 않은 큐 시스템

메시지 큐는 서로 독립적으로 분리되어 처리

AMQP(Advanced Message Queuing Protocol) : 표준화된 메시징 프로토콜(TCP 5672), 신뢰성이 있는 메시지

> 카카오 구매하기, 구매내역은 RabbitMQ를 사용해서 서비스 하고 있음

***Pub Sub모델***

Publish, Subscribe, 메시지에 특정한 수신자가 정해져 있지 않다. 구독을 신청한 수신자에게 전달

> LinkedIn은 초창기에 ActiveMQ를 사용하여 구현했었는데 서비스가 커지고 불편하여서 kafka를 직접 개발 함

***카프카의 탄생***

기존에 느끼던 불편함을 해소하기 위해 개발, 복잡했던 구조가 카프카를 중간에 두니 간편해짐

> 1. 높은 처리량 
> 2. 실시간 로그 통합 
> 3. 무중단 
> 4. 이기종과의 호환성 
> 5. 스케일 아웃 
> 6. 프로듀서와 컨슈머 분리

***성능 비교***

ThroughPut : Kafka > Pulsar > RabbitMQ

End-To-End Latency Quantiles: Kafka > Pulsar > RabbitMQ

***컨플루언트**

카프카를 오픈소스로 등록 후, 타 회사에서 구성 요청이 왔는데 링크드인에서 발생했던 문제들이 똑같이 발생하는 것을 보고 수익성을 발견해 창립한 회사

***카프카***

오픈 소스 분산 이벤트 스트리밍 플랫폼이며, 쓰기에 최적화 된 플랫폼이다.

***사용 사례 및 사용 이유***

예상치 못한 대량의 요청이 올 경우 장애가 발생하게 된다. 카프카를 사용하면 비동기 이기에 이떄 보관하고 있다가 복구 될 시 안정적으로 처리할 수 있다.

> 1. 무향 로션 검색 
> 2. 무향 로션 검색 로그 카프카로 전달 (프로듀서)
> 3. 카프카에서 분석 시스템 내용 전달 (컨슈머)
> 4. 분석 결과 도출
> 5. 분석 결과 반영

> 적어도 한번 전송 방식: 중복은 괜찮은데 데이터가 유실 되면 안된다.

## 카프카 기본 구성

사진

프로듀서: 카프카로 데이터를 전송해주는 것

컨슈머: 카프카로 들어온 메시지를 꺼내서 사용하는 것 

> 예전에는 consumer offest을 주키퍼 저장소에 저장했었기 때문에 주키퍼와 컨슈머가 연결이 되어 있어야 했었다.

***카프카 클러스터**

주키퍼는 quorum mode로 인해 반드시 홀수로 구성해야 하고 브로커는 제한이 없다. 

주키퍼 3대, 브로커 3대가 기본이다.

## 주키퍼 

코디네이션 애플리케이션이다. 카프카의 메타 데이터를 관리한다. KIP-500이라고 주키퍼 제거를 논의 해서 제거 버전이 나오긴 했다.

분산 시스템과 병행하여 코디네이션 시스템 개발은 비효율적이다. 새로 만들기 보다는 주키퍼가 잘 되어 있어서 그대로 쓰기로 한 것이다.

카프카는 클러스터라 하지만 주키퍼는 앙상블이라 한다.

***주키퍼 구성***

분산 시스템의 저장소: 브로커, 토픽 정보 등

리더(write): 로컬에서 처리

팔로워(read): 리더가 처

***카프카 아키텍처***

> 카카오는 5대로 카프카 클러스터를 사용함
> 
> 주키퍼 하나에 카프카 여러 대를 붙여서 사용하기도 함

## 이하 내용

카프카 pub sub 모델은 초기 출시할 때 부터 목적은 decoupling이다.

토픽은 토픽 이름만으로 구분한다. 토픽은 확장할 수 있기에 멀티 컨슈머 멀티 프로듀서를 쓸 수 있다. 원하는대로 확장가능하다.

thickTime: 주기 
initLimit: 초기화 될때 까지의 시간 
syncLimit: 팔로우와 리더가 동기화 하는 시간

## 브로커

카프카라 하면 그 안에 여러대의 브로커가 있는 것이다. 프로듀서가 데이터를 쏘는 것은 카프카가 아니라 브로커에 쏘는 것이다.

프로듀서가 브로커에 쏘면, 컨슈머가 꺼내 가는 흐름이다.

## 파티션

토픽은 내부적으로 병렬 처리를 위해 파티션이라는 것으로 나뉘어져 있고, 파티션은 세그먼트로 나뉘어져 있다.

파티션안에는 메시지들이 저장되는데, 메시지들은 오프셋이라 불리는 자기 번호가 있다.

카프카는 프로듀서가 보낸 메시지 내용은 볼 수 없고 오프셋만 알 수 있다.

## 주키퍼 주소 

서버가 3대일 경우 귀찮아서 kafka 설정에 주키퍼 주소 넣을때 하나만 넣어도 되긴 하지만, 이 경우 한 대에 문제가 생기면 zookeeper는 과반수 법칙에 따라 2대가 살아 있으니 정상으로 작동하지만 kafka에서 문제가 된다. 

## 정상적으로 동작하는지 확인

주키퍼 cli에서 ls / 를 사용해서 우리가 설정한 node가 있는지 확인후, ls /{znode}/brokers/ids 를 확인하면 된다.

좀 더 자세히 보려면 get /{znode}/brokers/ids/{id} 입력해서 결과를 보면 된다.

## Motivation

1. 대량의 실시간 데이터를 다루기 위해 카프카 개발
2. 여러가지 사례들을 통해 연구하고 고민
3. 실시간 로그 통합 같은 이벤트를 처리하기 위해 높은 처리량 필요
4. 빠른 전송 속도 보장
5. 분산, 분할, 실시간 처리를 위해 생겨난 파티셔닝과 컨퓨머 모델
6. 장비의 장애 상황에도 안정적인 유지'

## Persistence

1. 디스크는 느리다라는 선입견
2. linear read와 write는 os에 의해 최적화 되어 있다.
3. os는 최근 적극적으로 디스크 캐싱에 메인 메모리를 사용하다록 하고 있다.
4. 메모리 반환시에는 약간의 성능 저하가 있지만 모든 메모리를 디스크 캐싱으로 전환하려고 한다.
5. JVM에서 JAVA는 객체의 메모리 오버헤드가 높으면 GC를 해주지만, heap이 클수록 불편하고 느리다.
6. 페이지 캐시에 의존하는 것이 유리하다.
7. 운영체제에 있는 것을 사용하면 서비스가 재시작 되어도 캐시가 남아 있다.


## Page Cache(available memory)

1. 시스템 성능을 향상시키기 위해 사용되는 메모리 관리 기법 중 하나.
2. os는 사용하지 않는 부분의 메모리를 페이지 캐시로 유지하여, 페이지 캐시의 컨텐츠에 대해 빠른 액세스를 제공

> 페이지 캐시는 메모리를 물리적으로 전체를 사용한다, 그래서 카프카와 주키퍼를 같은 서버에 올리지 않는 것을 추천한다.

## Dirty Page

1. 페이지 캐시에 있는 데이터를 수정하면, 해당 메모리 페이지는 dirty 상태가 된다.
2. 수정되었지만, 아직 영구 저장소(ex: 하드디스크)에 write 하지 않은 메모리 페이지를 의미
3. 성능적인 부분에서는 효율적이지만, 페이지 캐시와 디스크 내용이 다르면 정합성 문제가 발생할 수도 있다
4. 매번 flush하게 되면, IO 부하가 높아 오히려 성능 저하 발생

## Efficiency

1. 효율성에 상당한 노력을 기울였고, 주목적은 대량의 web activity data를 처리하는 것
2. 다운스트림 인프라 구조에서 애플리케이션 사용에 있어 작은 충돌로 병목이 쉽게 일어난다면, 작은 변화에도 문제가 발생할 수 있음
3. 수십, 수백개의 파이프 라인을 갖는 중앙 집중 클러스터가 사용 패턴에 의해 자주 변경되는 서비스를 지원할 때 매우 중요
4. 비효율적인 disk access를 제외하고 나면, 나머지 비효율성은 2가지 (너무 작은 I/O operation, 과도한 byte copying)
5. 다른 비효율성은 byte copying에서 발생
6. 빈도가 낮을때는 문제가 없지만, 부하가 높으면 문제 발생
7. 브로커와 컨슈머, 프로듀서 사이에 표준화된 메시지 형식 사용
8. 공통된 형식을 유지하여 최적화된 네트워크로 전달 필요
9. 최신의 OS는 페이지 캐시에서 데이터를 소켓으로 전송하기 위해 최적화된 코드 제공
10. 몇몇 경우의 병목현상은 CPU or Disk가 아닌 Network Bandwidth 로 발생
11. 특히 데이터 센터간 대량의 메시지 전송시 발생
12. 카프카의 지원없이 압축할 수 있지만, 압축률은 떨어질 수 있다.
13. 효율적인 압축방식은 각각의 메시지를 압축하는 것보다 다수의 메시지를 압축 - Gzip, Snappy, LZ4, Zstd

> 빠른 전송: snappy < lz4(압축율이 더 좋음)

> 높은 압축율(대량의 데이터를 효과적으로 전송): zstd > gzip - zstd를 표준으로 쓰기 아쉬운 건 지원하지 않는 경우가 많다. gzip 많이 씀

# 토픽

## 디커플링


## 중요한 것

리더가 골고루 분산 되는 것이 정말 중요함



